---
title: "Proyek Akhir Praktikum Data Science"
author: "123200063_123200080"
date: "2022-12-04"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r library}
library(dplyr)
library(tidymodels)
library(vroom)
library(here)
library(corpus)
library(openssl)
library(httpuv)
library(rtweet)
library(SnowballC)
library(httr)
library(RTextTools)
library(textdata)
library(purrr)
library(tm)
library(NLP)
library(SentimentAnalysis)
library(RColorBrewer)
library(wordcloud)
library(tidyverse) 
library(tidytext)
library(e1071)
library(caret)
library(syuzhet)
library(gmodels)
library(plyr)
library(plotly)
library(DT)
library(sass)
library(stringr)
library(sentimentr)
library(naivebayes)
library(ggplot2)
library(plotrix)
library(shiny)
library(caTools)
```

```{r load data from API}


api_key <- "FBox1hjtTDLO3VZvyKWIZx77j"
api_secret_key <- "b3oOc7sGKHrzCdlHjFP8L6U5zWOdhSiEv3g3TJAfwQ02EV6IW5"
bearer_token <- "AAAAAAAAAAAAAAAAAAAAAF4YjgEAAAAADwzHHipo40WWiP%2F7NYjSaRvL5Gk%3DmLyBXX31ggRKxdEYkNmIid8uEKkzKiQ951aO1lJgE1qvzBC3JS"
accessToken <- "1592089064374534145-6hpvtXEwCUBMK7wbZCIXaRXTlarEWc"
accessSecret <- "h35r7DP0dR4AcUwBQqUXE5diaPTDkY7TEm4s41cT9X3xp"
token = create_token(
  app = "sentimentAnalysisBooster",
  consumer_key = api_key,
  consumer_secret = api_secret_key,
  access_token = accessToken,
  access_secret = accessSecret,
  set_renv = TRUE
)
auth_save(token, "tweetAccess")
auth_as("tweetAccess")
auth_sitrep()
```
```{r Search Data}
dataVaksinCovid <- search_tweets('#vaksincovid19', n=500, include_rts=FALSE)
dataVaksinBooster <- search_tweets('#vaksinbooster', n=500, include_rts=FALSE)
dataVaksin <- search_tweets('#vaksin', n=500, include_rts=FALSE)
dataBooster <- search_tweets('#booster', n=500, include_rts=FALSE)
data <- rbind(dataVaksinCovid, dataVaksin, dataVaksinBooster, dataBooster)
data <- data %>% select(full_text)
```

```{r Cleaning Data}
data1 <-  Corpus(VectorSource(data$full_text))
removeLink <- function(d) gsub("http[^[:space:]]*","",d)
dataClean <- tm_map(data1, removeLink)
removenl <- function(d) gsub("\n"," ",d)
dataClean <- tm_map(dataClean, removenl)
removeComma <- function(d) gsub(",","",d)
dataClean <- tm_map(dataClean, removeComma)
removeTitik2 <- function(d) gsub(":","",d)
dataClean <- tm_map(dataClean, removeTitik2)
removeTitikKoma <- function(d) gsub(";","",d)
dataClean <- tm_map(dataClean, removeTitikKoma)
removeAmp <- function(d) gsub("&amp","",d)
dataClean <- tm_map(dataClean, removeAmp)
removeun <- function(d) gsub("@\\w+","",d)
dataClean <- tm_map(dataClean, removeun)
remove.all <- function(d) gsub("[^[:alpha:][:space:]]","",d)
dataClean <- tm_map(dataClean, remove.all)
dataClean <- tm_map(dataClean, removePunctuation)
dataClean <- tm_map(dataClean, tolower)
df <- data.frame(text=unlist(sapply(dataClean,'[')),stringAsFactors=F)
write.csv(df,file="dataCleanTwitter.csv")
```
```{r load Data}
Twitter <- vroom("dataCleanTwitter.csv")
tweetsc <- data.frame(Twitter['text'])

```


```{r Sentimen Polarity Positive and Negative}
tweet.df <- data.frame(Twitter['text'])
    
    # Remove character in tweet
    tweet.df$text = str_replace_all(tweet.df$text, "[\\.\\,\\;]+", " ")
    tweet.df$text = str_replace_all(tweet.df$text, "http\\w+", "")
    tweet.df$text = str_replace_all(tweet.df$text, "@\\w+", " ")
    tweet.df$text = str_replace_all(tweet.df$text, "[[:punct:]]", " ")
    tweet.df$text = str_replace_all(tweet.df$text, "[[:digit:]]", " ")
    tweet.df$text = str_replace_all(tweet.df$text, "^ ", " ")
    tweet.df$text = str_replace_all(tweet.df$text, "[<].*[>]", " ")
    
    sentiment.score <- sentiment(tweet.df$text)
    sentiment.score <- sentiment.score %>% 
      group_by(element_id) %>% 
      summarise(sentiment = mean(sentiment))
    
    tweet.df$polarity <- sentiment.score$sentiment
    tweet.final <- tweet.df[, c('text', 'polarity')]
    
    tweet.final <- tweet.final[tweet.final$polarity != 0, ]
    tweet.final$sentiment <- ifelse(tweet.final$polarity < 0, "Negative", "Positive")
    tweet.final$sentiment <- as.factor(tweet.final$sentiment)
    
    tweet.balanced <- upSample(x = tweet.final$text, y = tweet.final$sentiment)
    names(tweet.balanced) <- c('text', 'sentiment')
    
    tweet.final$id <- seq(1, nrow(tweet.final))
```

```{r split data}
#make this example reproducible
set.seed(1)

#use 70% of dataset as training set and 30% as test set
sample <- sample.split(tweet.final, SplitRatio = 0.7)
train.tweet  <- subset(tweet.final, sample == TRUE)
test.tweet   <- subset(tweet.final, sample == FALSE)
```

```{r Document Terms Matrix}
 get.dtm <- function(text.col, id.col, input.df, weighting) {
      
      # removing emoticon
      input.df$text <- gsub("[^\x01-\x7F]", "", input.df$text)
      
      # preprocessing text
      corpus <- VCorpus(DataframeSource(input.df))
      corpus <- tm_map(corpus, removePunctuation)
      corpus <- tm_map(corpus, removeNumbers)
      corpus <- tm_map(corpus, stripWhitespace)
      corpus <- tm_map(corpus, removeWords, stopwords("english"))
      corpus <- tm_map(corpus, content_transformer(tolower))
      
      dtm <- DocumentTermMatrix(corpus, control = list(weighting = weighting))
      return(list(
        "termMatrix" = dtm,
        "corpus" = corpus
      ))
 }
    colnames(train.tweet)[4] <- "doc_id"
    train.dtm <- get.dtm('text', 'id', train.tweet, "weightTfIdf")
    train.corpus <- train.dtm$corpus
    train.dtm <- train.dtm$termMatrix
    train.dtm.mat <- as.matrix(train.dtm)
    
    colnames(test.tweet)[4] <- "doc_id"
    test.dtm <- get.dtm('text', 'id', test.tweet, "weightTfIdf")
    testcorpus <- test.dtm$corpus
    test.dtm <- test.dtm$termMatrix
    test.dtm.mat <- as.matrix(test.dtm)
    
```

```{r Naive Bayes}
 # Using Naive Bayes
    model <- naive_bayes(x = train.dtm.mat, y = train.tweet$sentiment, usekernel = TRUE)
    
    # predict using model
    preds <- predict(model, newdata = test.dtm.mat, type = "class")
    
    # calculate accuracy with Confusion Matrix
    cm <- confusionMatrix(preds, test.tweet$sentiment)
    accuracy <- cm$overall['Accuracy']
    accuracy

```
```{r Polarity Positive and Negative}
x <- c(model$prior[['Negative']], model$prior[['Positive']])
labels <- c("Negative", "Positive")
```

```{r UI}
ui <- fluidPage(
  
  titlePanel("Sentimen Analisis"),
  
  sidebarLayout(
    sidebarPanel(
      sliderInput("maxword",
                  "Jumlah kata yang ingin ditampilkan",
                  min = 30,
                  max = 200,
                  value = 50),
      submitButton(text="Tampilkan")
    ),
    
    
    mainPanel(
      tabsetPanel(
        tabPanel(
          "WordCloud",
          HTML(
            "<div><h3>Word Cloud dari Data</h3></div>"
          ),
          plotOutput("wordCloud")
        ),
        
        tabPanel(
          "Polarity Positive Negative",
          HTML(
            "<div><h3>Persentasi Polarity Positif dan Negatif Menggunakan Pie 3D</h3></div>"
          ),
          plotOutput("piePlot"),
          textOutput("positive"),
          textOutput("negative"),
          tags$head(tags$style("#positive, #negative {
                                            font-size: 20px
                    }"))
        ),
        tabPanel(
          "Accuracy analysis",
          HTML(
            "<div><h3>Akurasi yang dihitung menggunakan confusion matrix</h3></div>"
          ),
          textOutput("accuracy"),
          tags$head(tags$style("#accuracy {
                                            font-size: 40px
                    }"))
        ),
        tabPanel(
          "Chatter Twitter",
          HTML(
            "<div><h3>Isi Tweet yang telah dibersihkan</h3></div>"
          ),
         DT::dataTableOutput("table")
          
        ),
        plotOutput("distPlot")
      )
    )
  )
)
```
```{r Server}
server <- function(input, output) {

  
  output$accuracy <- renderText({
    paste(toString(floor(accuracy * 100)), "%", sep = "")
  })
  
  output$wordCloud <- renderPlot({
    wordcloud(
      train.corpus,
      random.offer = 'F',
      max.words = input$maxword,
      main="wordCount",
      colors=brewer.pal(8,"Dark2")
    )
  })
  
  # Render output
  
  output$piePlot <- renderPlot({
    pie3D(x, labels = labels, explode = 0.1, main = "Pie chart 3D", col =c("brown","pink") )
  })
  
  output$negative <- renderText(
    paste("Negative : ", 
          toString(floor(model$prior[['Negative']] * 100)), "%", sep = "")
  )
  output$table <- DT::renderDataTable({
    DT::datatable(tweetsc, options = list(lengthChange = FALSE))
  })
  
  output$positive <- renderText(
    paste("Positive : ", 
          toString(floor(model$prior[['Positive']] * 100)),  "%", sep = "")
  )
  
  
}
```

```{r Run}
shinyApp(ui = ui, server = server)
```
